version: '3.0'

services:
  namenode:
    image: plc9/hadoop-namenode:1.1.0-hadoop2.8-java8
    container_name: namenode
    volumes:
      - ../../../../run/media/priyan/data1/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop-hive.env
    ports:
      - 50070:50070
  datanode1:
    image: plc9/hadoop-datanode:1.1.0-hadoop2.8-java8
    container_name: datanode1
    volumes:
      - ../../../../run/media/priyan/data1/node:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    env_file:
      - ./hadoop-hive.env
    ports:
      - 50075:50075
  datanode2:
    image: plc9/hadoop-datanode:1.1.0-hadoop2.8-java8
    container_name: datanode2
    volumes:
      - ../../../../run/media/priyan/data2/node:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    env_file:
      - ./hadoop-hive.env
    ports:
      - 50076:50075
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.1.0
    volumes:
       - ../../../../run/media/priyan/2684ef86-3827-4943-94ad-9cd1454b9741/postgres:/var/lib/postgresql/data
  hive-server:
    image: plc9/hive-server-hadoop-2.8.0:first
    container_name: hive-server
    env_file:
      - ./hadoop-hive.env
    environment:
      - "HIVE_CORE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-metastore/metastore"
      - "CORE_CONF_fs_defaultFS=hdfs://namenode:8020"
      - "CORE_CONF_hadoop_proxyuser_hue_hosts=*"
      - "CORE_CONF_hadoop_proxyuser_hue_groups=*"
    ports:
      - "10000:10000"
  hive-metastore:
    image: plc9/hive:2.1.0-postgresql-metastore
    container_name: hive-metastore
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
  spark-master:
    image: localhost:5000/spark-master-hadoop2.8.0-hive2
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    env_file:
      - ./hadoop-hive.env
  spark-worker1:
    image: localhost:5000/spark-worker-hadoop2.8.0-hive2
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_EXECUTOR_MEMORY=32g
      - SPARK_SUBMIT_OPTIONS= --executor-memory 32G
    ports:
      - "8081:8081"
    env_file:
      - ./hadoop-hive.env
  spark-worker2:
    image: localhost:5000/spark-worker-hadoop2.8.0-hive2
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_EXECUTOR_MEMORY=32g
      - SPARK_SUBMIT_OPTIONS= --executor-memory 32G
    ports:
      - "8082:8082"
    env_file:
      - ./hadoop-hive.env
  spark-worker3:
    image: localhost:5000/spark-worker-hadoop2.8.0-hive2
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8083:8083"
    env_file:
      - ./hadoop-hive.env
  spark-worker4:
    image: localhost:5000/spark-worker-hadoop2.8.0-hive2
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8084:8084"
    env_file:
      - ./hadoop-hive.env
  spark-notebook:
    image: bde2020/spark-notebook:2.1.0-hadoop2.8-hive
    container_name: spark-notebook
    env_file:
      - ./hadoop-hive.env
    ports:
    - 9001:9001
  hue:
    image: bde2020/hdfs-filebrowser:3.11
    ports:
      - 8088:8088
    environment:
      - NAMENODE_HOST=namenode
  zeppelin:
      image: plc9/zeppelin_2_1
      ports:
        - 9090:9090
      volumes:
        - ./notebook:/opt/zeppelin/notebook
      environment:
        CORE_CONF_fs_defaultFS: "hdfs://namenode:8020"
        #SPARK_MASTER: "spark://spark-master:7077"
        #MASTER: "spark://spark-master:7077"
        #SPARK_EXECUTOR_MEMORY: "32G"
        SPARK_SUBMIT_OPTIONS: "--executor-memory 32G"
        #SPARK_SUBMIT_OPTIONS: "--jars /opt/sansa-examples/jars/sansa-examples-spark-2016-12.jar"
      depends_on:
         - spark-master
       
#volumes:
#  hadoop_namenode:
#    driver: local
#    driver_opts:
#        device: /run/media/priyan/data1/namenode
#  hadoop_datanode1:
#    driver: local
#    driver_opts:
#      device: /run/media/priyan/data1/node
#  hadoop_datanode2:
#    driver: local
#    driver_opts:
#      device: /run/media/priyan/data2/node
#  postgres-data:
#    driver: local
#    driver_opts:
#      device: /run/media/priyan/2684ef86-3827-4943-94ad-9cd1454b9741/postgres